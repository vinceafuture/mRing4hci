**mRing**: wearable multimodal Smart Ring for HCI
A thumb-worn smart ring, callled "mRing", is designed to support multimodal interactions with computers/TV/AI. Users can use it to replace mouse&keyboard or remoter, extend human-computer interaction beyond screens, and enable intuitive control of robots and smart home systems.

![mRing overview](images/mRing_overview.png)

---

## ğŸŒŸ Why mRing?

### The personal motivation  
My teenage son plays PC games like HOI4 and Cards for hours every day, and also watches game related videos to improve gaming performance.  
Seeing him develop early symptoms of wrist stress and other issue forced me to rethink the input devices we all still rely on.

**Why are we still using mouse and keyboard â€” technologies invented 40 years ago â€” in a world with AI computing, multimodal input and versatile screens, and intelligent agents?**

This question led me to create **mRing**, an input device that compliants to GUI operation on PC/TV/Pad and aligns with the next decade of AI-native interaction.

### The broader vision  
mRing aims to become all-in-one input device:

- A **replacement** or alternative to the mouse&keyboard / multi-touch / remoter / laser-pen
- A **most convenient method** for Voice input
- A **best method** for circle-to-X on screen
- A **intuitive controller** for robots and home smart devices  
- The foundational hardware for a future interaction OS (ZingOS)

---

## ğŸ¯ What is mRing?

mRing combines:

- **Thumb-worn form factor** (finger-based interaction)
- **Gesture recognition** (inside finger camera + IMU options depending on version)
- **screen positioning** (outside scene camera-based)  
- **Laser pointer** for off-screen notice or real-world object selection  
- **Voice capture** for multimodal AI commands  
- **Multiple input modes** via thumb-joint touches  
- **Task-level control** for robots and smart home systems  
- **Custom low-power chip (MR1)** under design for wearable HCI

The result is a new humanâ€“machine interface that merges pointing, selection, gesture, and speech into a single device.

---

## ğŸ§© Key Features

### 1. **Gesture-based control**
Perform gestures in mid-air to:
- Scroll  
- Drag  
- Rotate  
- Zoom  
- Trigger macros  
- Control robots
  
### 2. **Laser-guided pointing**
Point at screens, objects, robots, or appliances.  
mRing interprets the laser spot + context + voice to generate actions.

### 3. **Thumb-joint multi-mode input**
Three thumb joint positions act as different â€œtoolsâ€:
- Distal joint â†’ primary action (click/select)  
- Middle joint â†’ secondary action (switch tool / mode)  
- Proximal joint â†’ gesture modifier or menu trigger  

This allows mode-switching similar to mouse buttons but far more flexible.

### 4. **Speech + pointing fusion**
Say:  
â€œPick this upâ€ â†’ point at the object  
â€œMove this thereâ€ â†’ draw two points  
â€œSummarize thisâ€ â†’ circle a region on the screen  

mRing becomes a powerful AI pointer.

### 5. **AI-native design**
mRing works as the hardware input layer for an AI interaction OS (ZingOS), enabling:

- Context-aware actions  
- Multimodal agent flows  
- Scene-based interpretation  
- Structured task generation  

## ğŸ“¦ Contents of This Repository

- **/whitepapers/**  
  Full technical whitepaper describing mRing's design philosophy, architecture, and use cases.

- **/images/**  
  Overview, Interaction diagrams, hardware block diagrams, and system-level flows.

- **/videos/mRing-operation-concept.mp4**  
  Concept demo video (not hardware-accurate, but illustrates interaction flows). 

---

## ğŸ§ª Current Status

mRing is currently:

- A complete conceptual design  
- Six related patents filed  
- Looking for collaborators in:  
  - Hardware industrial design  
  - Optical/laser module engineering  
  - Robotics integration  
  - ODM/contract manufacturing

This repo is **not** a finished product â€” it is an open design proposal seeking contributors and partners.

---

## ğŸ¤ Call for Collaborators

If you are passionate about:

- Post-mouse interaction  
- Wearable computing  
- Humanâ€“AI symbiosis  
- Robotics  
- New input devices  
- Chip-level low-power architecture  

You are welcome to join.

Please reach out via GitHub Issues or email:  
**[vincezhou8@gmail.com]**

---

## ğŸ“œ License

TBD depending on collaboration model (MIT/Open Hardware License/Custom).  
Initial documentation is open for feedback and non-commercial exploration.

---

## â­ Star This Project

If you believe the mouse will eventually be replaced, or that AI needs new human input hardware, please star the repo to support this direction.

---

## ğŸ™ Acknowledgments

Inspired by pioneers in human-computer interaction who pushed beyond the graphical interface era.  
mRing aims to explore the next era: **AI-native interaction.**


